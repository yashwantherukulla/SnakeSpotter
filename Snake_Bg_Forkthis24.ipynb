{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashwantherukulla/SnakeSpotter/blob/main/Snake_Bg_Forkthis24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zPoCbjJwbsa"
      },
      "source": [
        " # Snake vs Background Classifier using PyTorch\n",
        "\n",
        " This notebook is a binary classifier to distinguish between snake images and background images using a VGG16 model with modified head."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmmsx8ZBwbsd"
      },
      "source": [
        " ## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPP-F-mQwbsd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from typing import Dict, List, Tuple\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import itertools\n",
        "import random\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except ImportError:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.manual_seed(4709471861038091579)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ryWPu8Wwbse"
      },
      "source": [
        " ## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boSt5oQUwbse"
      },
      "outputs": [],
      "source": [
        "data_path = Path(\"data/\")\n",
        "if Path(\"data/Data\").is_dir():\n",
        "    print(\"Data directory exists\")\n",
        "else:\n",
        "    print(f\"Did not find {data_path} directory, creating one...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with open(data_path / \"BaseDataset.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://figshare.com/ndownloader/files/35784053\")\n",
        "        print(\"Downloading data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    with zipfile.ZipFile(data_path / \"BaseDataset.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping data...\")\n",
        "        zip_ref.extractall(data_path)\n",
        "\n",
        "    os.remove(data_path / \"BaseDataset.zip\")\n",
        "\n",
        "train_dir = data_path / \"Data/train\"\n",
        "valid_dir = data_path / \"Data/valid\"\n",
        "test_dir = data_path / \"Data/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1C-YNhmwbsf"
      },
      "source": [
        " ## Data Transforms and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws75NAjxwbsf"
      },
      "outputs": [],
      "source": [
        "target_size = (150, 150)\n",
        "mean = np.array([0.0, 0.0, 0.0])\n",
        "std = np.array([0.0, 0.0, 0.0])\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"valid\": transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = os.cpu_count()\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transforms[\"train\"])\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms[\"valid\"])\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transforms[\"test\"])\n",
        "\n",
        "class_names = train_data.classes\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of validation samples: {len(valid_data)}\")\n",
        "print(f\"Number of test samples: {len(test_data)}\")\n",
        "print(f\"Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uutxLtnawbsg"
      },
      "source": [
        " ## Visualize Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_CAUGnawbsg"
      },
      "outputs": [],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(f\"Label: {class_names[label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xocjHLoLwbsg"
      },
      "source": [
        " ## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0yExaN8wbsh"
      },
      "outputs": [],
      "source": [
        "weights = torchvision.models.VGG16_Weights.DEFAULT\n",
        "model = torchvision.models.vgg16(weights=weights).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(4096, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.98),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.75),\n",
        "    nn.Linear(64, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "xxu6xhdWw0iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4hFo2vVwbsh"
      },
      "source": [
        " ## Training and Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyOxzekIwbsh"
      },
      "outputs": [],
      "source": [
        "def train_step(model: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += (y_pred == y).sum().item() / len(y_pred)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def valid_step(model: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    valid_loss, valid_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "            valid_pred = model(X)\n",
        "            loss = loss_fn(valid_pred, y)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            valid_acc += (y_pred == y).sum().item() / len(valid_pred)\n",
        "\n",
        "    return valid_loss, valid_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CifyRvpwbsi"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          valid_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    results = {\"train_loss\": [], \"train_acc\": [], \"valid_loss\": [], \"valid_acc\": []}\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
        "        valid_loss, valid_acc = valid_step(model, valid_dataloader, loss_fn, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"valid_loss: {valid_loss:.4f} | \"\n",
        "            f\"valid_acc: {valid_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"valid_loss\"].append(valid_loss)\n",
        "        results[\"valid_acc\"].append(valid_acc)\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyurq2Rkwbsi"
      },
      "source": [
        " ## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWEbDPcnwbsi"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "start_time = timer()\n",
        "results = train(model, train_dataloader, valid_dataloader, optimizer, loss_fn, epochs, device)\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Loading Pretrained Weights\n"
      ],
      "metadata": {
        "id": "PUOfGGvZSOj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_with_pretrained_weights(PATH: str):\n",
        "  model = torchvision.models.vgg16(weights=weights).to(device)\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "  model.fc = nn.Sequential(\n",
        "      nn.Linear(4096, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.9),\n",
        "      nn.Linear(256, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.7),\n",
        "      nn.Linear(64, 1),\n",
        "      nn.Sigmoid()\n",
        "  ).to(device)\n",
        "\n",
        "  model.load_state_dict(torch.load(PATH))\n",
        "  return model"
      ],
      "metadata": {
        "id": "svRLr7Y4SVPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_with_pretrained_weights(\"/content/updated-snake-bg-model-weights-v2-ft.pth\")"
      ],
      "metadata": {
        "id": "DlyFKzEqS68K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eN-Liblwbsi"
      },
      "source": [
        " ## Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVzFMLIwbsi"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(results: Dict[str, List]):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(results[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(results[\"valid_loss\"], label=\"valid_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(results[\"train_acc\"], label=\"train_acc\")\n",
        "    plt.plot(results[\"valid_acc\"], label=\"valid_acc\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "DwbdkdZ5xCYf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot_image(img_path: str,\n",
        "                        model: nn.Module =model,\n",
        "                        class_names: List[str] = class_names,\n",
        "                        img_size: Tuple[int, int] = (224, 224),\n",
        "                        transform: torchvision.transforms = None,\n",
        "                        device: torch.device=device):\n",
        "  from PIL import Image\n",
        "\n",
        "  img = Image.open(img_path)\n",
        "  with torch.inference_mode():\n",
        "    trans_img = img_transform(img).unsqueeze(dim=0)\n",
        "    target_img_prob = model(trans_img)\n",
        "\n",
        "  actual_label = img_path.split('/')[-2]\n",
        "  target_img_label = torch.round(target_img_prob).to(torch.int8).item()\n",
        "  target_img_prob = target_img_prob.to(torch.float16).item()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"True: {actual_label} | Pred: {class_names[target_img_label]} | Prob: {target_img_prob:.3f}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "qy15TWA0NEEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot_images_dataloader(dataloader: DataLoader = test_dataloader,\n",
        "                         model: nn.Module = model,\n",
        "                         class_names: List[str] = class_names,\n",
        "                         img_size: Tuple[int, int] = (224, 224),\n",
        "                         device: torch.device = device,\n",
        "                         num_images: int = 5):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total_images = len(dataloader.dataset)\n",
        "\n",
        "    random_indices = random.sample(range(total_images), num_images)\n",
        "    rev_norm = transforms.Compose([\n",
        "        transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
        "        transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
        "    ])\n",
        "    with torch.inference_mode():\n",
        "        for idx in random_indices:\n",
        "            img, actual_label = dataloader.dataset[idx]\n",
        "            img = img.unsqueeze(0).to(device)\n",
        "\n",
        "            target_img_prob = model(img)\n",
        "            target_img_label = torch.round(target_img_prob).to(torch.int8).item()\n",
        "            target_img_prob = target_img_prob.to(torch.float16).item()\n",
        "\n",
        "            img = rev_norm(img).squeeze(0).to(\"cpu\")\n",
        "            plt.figure()\n",
        "            plt.imshow(img.permute(1, 2, 0))\n",
        "            if class_names[actual_label] == \"background\":\n",
        "                target_img_prob = 1 - target_img_prob\n",
        "            plt.title(f\"True: {class_names[actual_label]} | Pred: {class_names[target_img_label]} | Prob: {target_img_prob:.3f}\")\n",
        "            plt.axis(False)\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "QE00etKRoCt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot_image(\"/content/data/Data/test/snake/180 (649).JPG\")"
      ],
      "metadata": {
        "id": "rFyagRPuhfyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot_images_dataloader()"
      ],
      "metadata": {
        "id": "VC6Rgf6xoEye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "7x8g2nD4yvBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def test_step(model: nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float, np.ndarray, np.ndarray]:\n",
        "  test_loss = 0\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      test_pred = model(X)\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "\n",
        "      all_predictions.extend(y_pred)\n",
        "      all_labels.extend(y)\n",
        "\n",
        "  test_loss /= len(dataloader)\n",
        "\n",
        "  return test_loss, all_predictions\n",
        "\n",
        "def test(model: nn.Module,\n",
        "         dataloader: torch.utils.data.DataLoader,\n",
        "         loss_fn: nn.Module,\n",
        "         device: torch.device) -> Dict[str, float]:\n",
        "  test_loss, all_predictions, all_labels = test_step(model, dataloader, loss_fn, device)\n",
        "\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "  precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
        "  recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
        "  f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
        "\n",
        "  class_report = classification_report(all_labels, all_predictions, output_dict=True)\n",
        "  conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "  results = {\n",
        "    \"test_loss\": test_loss,\n",
        "    \"accuracy\": accuracy,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall,\n",
        "    \"f1_score\": f1,\n",
        "    \"classification_report\": class_report,\n",
        "    \"confusion_matrix\": conf_matrix\n",
        "  }\n",
        "\n",
        "  return results\n",
        "\n",
        "def visualize_results(results: Dict[str, float]):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "  sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
        "  ax1.set_title('Confusion Matrix')\n",
        "  ax1.set_xlabel('Predicted')\n",
        "  ax1.set_ylabel('Actual')\n",
        "\n",
        "  class_report = results['classification_report']\n",
        "  del class_report['accuracy']\n",
        "\n",
        "  report_df = pd.DataFrame(class_report).T\n",
        "  report_df = report_df.drop('support', axis=1)\n",
        "\n",
        "  sns.heatmap(report_df, annot=True, cmap='YlGnBu', ax=ax2)\n",
        "  ax2.set_title('Classification Report')\n",
        "  ax2.set_xlabel('Metrics')\n",
        "  ax2.set_ylabel('Classes')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"Test Loss: {results['test_loss']:.4f}\")\n",
        "  print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "  print(f\"Precision: {results['precision']:.4f}\")\n",
        "  print(f\"Recall: {results['recall']:.4f}\")\n",
        "  print(f\"F1 Score: {results['f1_score']:.4f}\")"
      ],
      "metadata": {
        "id": "m04GrLNszXSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = test(model, test_dataloader, loss_fn, device)\n",
        "visualize_results(results)"
      ],
      "metadata": {
        "id": "VD703cEUyyX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc\n"
      ],
      "metadata": {
        "id": "IGltTeG73aa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.initial_seed() #4709471861038091579"
      ],
      "metadata": {
        "id": "NQdngWQ3yJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/updated-snake-bg-model-weights-v2-ft.pth\"\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "EHieVunq3oOW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Lmmsx8ZBwbsd",
        "3ryWPu8Wwbse",
        "R1C-YNhmwbsf",
        "uutxLtnawbsg",
        "xocjHLoLwbsg",
        "F4hFo2vVwbsh",
        "uyurq2Rkwbsi",
        "PUOfGGvZSOj_",
        "8eN-Liblwbsi",
        "7x8g2nD4yvBh",
        "IGltTeG73aa0"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}